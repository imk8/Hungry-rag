# üöÄ hungry-rag
<p align="center">
  <img src="https://user-images.githubusercontent.com/25181517/183914128-3fc88b4a-4ac1-40e6-9443-9a30182379b7.png" width="50" />
  <img src="https://user-images.githubusercontent.com/25181517/223639822-2a01e63a-a7f9-4a39-8930-61431541bc06.png" width="50" />
  <img src="https://user-images.githubusercontent.com/25181517/183569191-f32cdf03-673f-4ae3-809b-3a8b376bb8a2.png" width="50" />
  <img src="https://user-images.githubusercontent.com/25181517/117207330-263ba280-adf4-11eb-9b97-0ac5b40bc3be.png" width="50" />
  <img src="https://avatars.githubusercontent.com/u/129853464?s=200&v=4" width="50" />
  <img src="https://cdn-lfs.huggingface.co/repos/96/a2/96a2c8468c1546e660ac2609e49404b8588fcf5a748761fa72c154b2836b4c83/9cf16f4f32604eaf76dabbdf47701eea5a768ebcc7296acc1d1758181f71db73?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27hf-logo.png%3B+filename%3D%22hf-logo.png%22%3B&response-content-type=image%2Fpng&Expires=1702139230&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjEzOTIzMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy85Ni9hMi85NmEyYzg0NjhjMTU0NmU2NjBhYzI2MDllNDk0MDRiODU4OGZjZjVhNzQ4NzYxZmE3MmMxNTRiMjgzNmI0YzgzLzljZjE2ZjRmMzI2MDRlYWY3NmRhYmJkZjQ3NzAxZWVhNWE3NjhlYmNjNzI5NmFjYzFkMTc1ODE4MWY3MWRiNzM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=Tu6ff3d4BIzaPnFloaourv40Ngl-mrsZjOuSaTKzGfFHXUfz5p2PgWPby1Iw1ZDs5yqneUvxT%7Eh%7Eh7pvJ12QbiqSluvyTtOacXUB5iLAnrTtgSO9HP7vOZ-D3U84asARxQZy5OZUN4TvkbelRDvKVFxJF6Knqdu6es4kHCnXeYg4rRi1qom2Vu%7EeyWxh5i6A-CcZoME0fnUYv58HtKSVVyNwtK0JwcaEmx68egl8zh6JtGYFaOcED0c65oaEKHm3bET1OZa%7EeQQtZ-kVkntKdNq0vdh%7EjbkLIYDNnbOEXhvKB4naLLrZa5TzRfqGotkGtSk0JF15blTaUppxNIqlTQ__&Key-Pair-Id=KVTP0A1DKRTAX" width="50" />
</p>

<!--
## Quick links: (Upload report and presentation slides on g drive, and paste link here)

[Existing LLM query results](https://github.com/waishun78/hungry-rag/blob/fe22cf58d5aa8ce0cad0aed45f6fcbbd38fee49c/queryresults.md)
-->

# Introduction
This repository aims to address the problem of outdated and subpar responses generated by Open Source LLMs when catering to **location-specific F&B queries**. As individuals increasingly rely on digital platforms for dining choices, there is a growing demand for precise and contextually relevant information regarding restaurants and cuisines in specific areas. Enhancing these responses with traditional information retrieval systems can create a better experience for consumers.

Goals of this project can be summarized as:
1. Enhanced _Accuracy_ and _Relevance_
2. Contextual Comprehension and _Personalization_
3. _Utility_ for Consumers and Businesses

## üçÄ Example queries 
```
Where to get Japanese food in Marina Bay Sands that is fine-dining and has a romantic atmosphere?
Where to get Italian food in Bugis that is family-friendly and has a casual setting?
```

# üç¥ Usage 
The main code of this repository is maintained in [`./hungry_rag.ipynb`](https://github.com/waishun78/hungry-rag/blob/main/hungry_rag.ipynb). 

The repository has mainly two pipelines:
1. One to take in the original query, and ask you for clarifying questions: This part has been implemented under the section titled `Query Rewriter Pipeline (Pipeline #1)`. You may input the query into the third cell in this section. The LLM will ask you for clarifying before moving to the next stage. You need to answer all of these clarifying questions inside `updated_query` variable.
   Pass the additional criteria into the node as:
   ```python
   updated_result = {
    "question":result["query"],
    "clarifier": result["output"],
    "additional_user_criteria":
      """
      1. Answer to question 1
      2. Answer to question 2
      3. Answer to question 3
      4. Answer to question 4
      5. Answer to question 5
      """
    }
   ```
3. Another to process the original query along with the clarifying questions: This part has been implemented in the section titled `Final Node Generation Pipeline (Pipeline #2)`. By running the cell with the full pipeline as shown, the LLM will generate three recommendations based on the original questions and the follow up clarifications.
   
   ```python
   generated_result = p2.run(query = updated_mexican_result)
   ```
# üèóÔ∏è Architecture 

<p align="center">
  <img src="https://github.com/waishun78/hungry-rag/assets/92146562/dff4614f-624b-43ef-b396-33cc5b679cb9" width="800"/>
</p>

### Query Rewriter
Based on user query this node seeks to prompt user with further clarifying questions about their preferences.

### Annotate Needs
Based on clarifying answers from the user, this node seeks to return a list of requirements of attributes that food establishment results must have.

### Search Term Generator
This node takes in all output from the previous nodes such as original query, clarifying questions/answers and list of required attributes. The node then outputs search terms that are used to query Elasticsearch or Google Places API(used for evaluation).

### ESNode (Elasticsearch Information Retrieval Node)
Elasticsearch Database is built by querying Google Places API using 80+ random food related queries. Search terms from previous node are used to retrieve output using BM25 algorithm built into Elasticsearch.

### Reader
This node processes all outputs produced by previous nodes including the original query, clarifying questions/answers, list of required attributes and context. It then generates the final output that the user views, which contains a list of recommended food establishments.

### Word Match Citation Generator
This last node of the main pipeline takes in the final list of recommended food establishments to be returned to user as well as context generated by Elastic Node. Wordmatch works by checking if the ratio of matched terms in the output to the total number of terms in the context exceeds a given threshold. If the ratio exceeds a certain threshold, a citation is generated. 
